{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing and Processing Text with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omg', '!', 'this', 'is', 'such', 'an', 'incredible', 'product', '.', 'perfect', 'keyboard', ',', 'perfect', 'weight', ',', 'perfect', 'battery', 'life', ',', 'perfect', 'trackpad', ',', 'perfect', 'performance', ',', 'perfect', 'touch', 'i', 'd', ',', 'perfect', 'feel', ',', 'perfect', 'build', ',', 'perfect', 'look', ',', 'perfect', 'size', ',', 'perfect', 'stereo', 'sound', ',', 'perfect', 'screen', ',', 'perfect', 'noise', 'absence', 'as', 'not', 'having', 'a', 'fan', '!', 'i', 'mean', ',', 'it', 'does', 'not', 'have', 'a', 'fan', 'and', 'it', 'does', 'not', 'get', 'hot', 'most', 'of', 'the', 'times', '.', 'wtf', '?', '!', 'it', 'is', 'the', 'only', 'laptop', 'i', 'have', 'been', 'able', 'to', 'use', 'in', 'my', 'bed', 'for', 'x', 'amount', 'of', 'hours', 'and', 'it', 'is', 'sooo', 'comfortable', 'to', 'do', 'it', '.', 'it', 'truly', 'is', 'one', 'of', 'the', 'best', 'products', 'out', 'there', 'and', 'it', 'is', 'totally', 'worth', 'the', 'investment', ',', 'because', 'that', 'is', 'how', 'i', 'see', 'it', ',', 'not', 'even', 'as', 'spending', ',', 'that', 'is', 'just', 'how', 'good', 'it', 'is', '.', 'i', 'am', 'enthusiastic', 'because', 'this', 'is', 'for', 'sure', 'the', 'best', 'device', 'apple', 'has', 'created', 'in', 'terms', 'of', 'price', '/', 'what', 'you', 'get', ',', 'and', 'it', 'will', 'probably', 'stay', 'in', 'that', 'position', 'for', 'a', 'couple', 'of', 'years', '.', 'this', 'is', 'game', '-', 'changing', 'and', 'revolutionary', '.', 'the', 'computer', 'feels', 'as', 'if', 'it', 'will', 'last', '10', '+', 'years', ',', 'honestly', '.', 'i', 'highly', 'recommend', 'it', '.', 'btw', ',', 'it', 'is', 'so', 'good', 'my', 'girlfriend', 'decided', 'to', 'get', 'one', 'for', 'herself', 'because', 'she', 'just', 'could', 'not', 'get', 'over', 'the', 'first', 'time', 'she', 'used', 'it', ',', 'and', 'just', 'how', 'beautiful', 'it', 'is', 'and', 'pleasurable', 'to', 'look', 'at', 'from', 'any', 'perspective', '...', 'this', 'laptop', 'is', 'so', 'ridiculously', 'perfect', 'that', 'you', 'can', 'even', 'open', 'it', 'with', 'one', 'hand', 'and', 'in', 'just', 'a', 'couple', 'of', 'seconds', ',', 'you', 'will', 'be', 'ready', 'to', 'use', 'it', 'as', 'it', 'has', 'an', 'always', '-', 'on', 'feature', 'that', 'allows', 'you', 'to', 'get', 'down', 'to', 'the', 'working', 'right', 'away', '.', 'that', 'is', 'probably', 'the', 'best', 'feat', '.', 'true', 'tone', 'is', 'also', 'really', 'good', ',', 'as', 'it', 'is', 'automatic', 'brightness', 'adjustment', 'and', 'dark', 'mode', ',', 'they', 'sit', 'together', 'perfectly', 'well', '.', 'get', 'it', '!', 'you', 'will', 'not', 'regret', 'it', 'at', 'any', 'moment', '.', 'truly', 'a', 'high', '-', 'end', 'experience', '.', 'oh', ',', 'and', '...', 'it', 'looks', 'elegant', 'at', 'any', 'angle', ',', 'and', 'which', 'is', 'most', 'important', ',', 'classy', 'it', 'feels', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "text = \"\"\"omg! this is such an incredible product. perfect keyboard, perfect weight, perfect battery life, perfect trackpad, perfect performance, perfect touch id, perfect feel, perfect build, perfect look, perfect size, perfect stereo sound, perfect screen, perfect noise absence as not having a fan! i mean, it does not have a fan and it does not get hot most of the times. wtf?! it is the only laptop i have been able to use in my bed for x amount of hours and it is sooo comfortable to do it. it truly is one of the best products out there and it is totally worth the investment, because that is how i see it, not even as spending, that is just how good it is. i am enthusiastic because this is for sure the best device apple has created in terms of price/what you get, and it will probably stay in that position for a couple of years. this is game-changing and revolutionary. the computer feels as if it will last 10+ years, honestly. i highly recommend it. btw, it is so good my girlfriend decided to get one for herself because she just could not get over the first time she used it, and just how beautiful it is and pleasurable to look at from any perspective... this laptop is so ridiculously perfect that you can even open it with one hand and in just a couple of seconds, you will be ready to use it as it has an always-on feature that allows you to get down to the working right away. that is probably the best feat. true tone is also really good, as it is automatic brightness adjustment and dark mode, they sit together perfectly well. get it! you will not regret it at any moment. truly a high-end experience. oh, and... it looks elegant at any angle, and which is most important, classy it feels.\n",
    "\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(text)\n",
    "\n",
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omg!', 'this is such an incredible product.', 'perfect keyboard, perfect weight, perfect battery life, perfect trackpad, perfect performance, perfect touch id, perfect feel, perfect build, perfect look, perfect size, perfect stereo sound, perfect screen, perfect noise absence as not having a fan!', 'i mean, it does not have a fan and it does not get hot most of the times.', 'wtf?!', 'it is the only laptop i have been able to use in my bed for x amount of hours and it is sooo comfortable to do it.', 'it truly is one of the best products out there and it is totally worth the investment, because that is how i see it, not even as spending, that is just how good it is.', 'i am enthusiastic because this is for sure the best device apple has created in terms of price/what you get, and it will probably stay in that position for a couple of years.', 'this is game-changing and revolutionary.', 'the computer feels as if it will last 10+ years, honestly.', 'i highly recommend it.', 'btw, it is so good my girlfriend decided to get one for herself because she just could not get over the first time she used it, and just how beautiful it is and pleasurable to look at from any perspective... this laptop is so ridiculously perfect that you can even open it with one hand and in just a couple of seconds, you will be ready to use it as it has an always-on feature that allows you to get down to the working right away.', 'that is probably the best feat.', 'true tone is also really good, as it is automatic brightness adjustment and dark mode, they sit together perfectly well.', 'get it!', 'you will not regret it at any moment.', 'truly a high-end experience.', 'oh, and... it looks elegant at any angle, and which is most important, classy it feels.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# create list of sentence tokens\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "print(sents_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: [\"'s\", 'therein', 'â€˜s', 'less', 'yourself', 'various', 'off', 'full', 'but', 'fifteen', 'yet', 'moreover', 'last', 'first', 'if', 'everything', 'somewhere', 'as', 'would', 'one']\n"
     ]
    }
   ],
   "source": [
    "# Identifying Stop words\n",
    "#importing stop words from English language.\n",
    "import spacy\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#Printing the total number of stop words:\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "\n",
    "#Printing first ten stop words:\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: [omg, !, incredible, product, ., perfect, keyboard, ,, perfect, weight, ,, perfect, battery, life, ,, perfect, trackpad, ,, perfect, performance, ,, perfect, touch, d, ,, perfect, feel, ,, perfect, build, ,, perfect, look, ,, perfect, size, ,, perfect, stereo, sound, ,, perfect, screen, ,, perfect, noise, absence, having, fan, !, mean, ,, fan, hot, times, ., wtf, ?, !, laptop, able, use, bed, x, hours, sooo, comfortable, ., truly, best, products, totally, worth, investment, ,, ,, spending, ,, good, ., enthusiastic, sure, best, device, apple, created, terms, price, /, ,, probably, stay, position, couple, years, ., game, -, changing, revolutionary, ., computer, feels, 10, +, years, ,, honestly, ., highly, recommend, ., btw, ,, good, girlfriend, decided, time, ,, beautiful, pleasurable, look, perspective, ..., laptop, ridiculously, perfect, open, hand, couple, seconds, ,, ready, use, -, feature, allows, working, right, away, ., probably, best, feat, ., true, tone, good, ,, automatic, brightness, adjustment, dark, mode, ,, sit, perfectly, ., !, regret, moment, ., truly, high, -, end, experience, ., oh, ,, ..., looks, elegant, angle, ,, important, ,, classy, feels, ., \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop words\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "#Implementation of stop words:\n",
    "filtered_sent=[]\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# filtering stop words\n",
    "for word in doc:\n",
    "    if word.is_stop==False:\n",
    "        filtered_sent.append(word)\n",
    "print(\"Filtered Sentence:\",filtered_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omg \n",
      "! \n",
      "this \n",
      "is \n",
      "such \n",
      "an \n",
      "incredible \n",
      "product \n",
      ". \n",
      "perfect \n",
      "keyboard \n",
      ", \n",
      "perfect \n",
      "weight \n",
      ", \n",
      "perfect \n",
      "battery \n",
      "life \n",
      ", \n",
      "perfect \n",
      "trackpad \n",
      ", \n",
      "perfect \n",
      "performance \n",
      ", \n",
      "perfect \n",
      "touch \n",
      "i \n",
      "d \n",
      ", \n",
      "perfect \n",
      "feel \n",
      ", \n",
      "perfect \n",
      "build \n",
      ", \n",
      "perfect \n",
      "look \n",
      ", \n",
      "perfect \n",
      "size \n",
      ", \n",
      "perfect \n",
      "stereo \n",
      "sound \n",
      ", \n",
      "perfect \n",
      "screen \n",
      ", \n",
      "perfect \n",
      "noise \n",
      "absence \n",
      "as \n",
      "not \n",
      "having \n",
      "a \n",
      "fan \n",
      "! \n",
      "i \n",
      "mean \n",
      ", \n",
      "it \n",
      "does \n",
      "not \n",
      "have \n",
      "a \n",
      "fan \n",
      "and \n",
      "it \n",
      "does \n",
      "not \n",
      "get \n",
      "hot \n",
      "most \n",
      "of \n",
      "the \n",
      "times \n",
      ". \n",
      "wtf \n",
      "? \n",
      "! \n",
      "it \n",
      "is \n",
      "the \n",
      "only \n",
      "laptop \n",
      "i \n",
      "have \n",
      "been \n",
      "able \n",
      "to \n",
      "use \n",
      "in \n",
      "my \n",
      "bed \n",
      "for \n",
      "x \n",
      "amount \n",
      "of \n",
      "hours \n",
      "and \n",
      "it \n",
      "is \n",
      "sooo \n",
      "comfortable \n",
      "to \n",
      "do \n",
      "it \n",
      ". \n",
      "it \n",
      "truly \n",
      "is \n",
      "one \n",
      "of \n",
      "the \n",
      "best \n",
      "products \n",
      "out \n",
      "there \n",
      "and \n",
      "it \n",
      "is \n",
      "totally \n",
      "worth \n",
      "the \n",
      "investment \n",
      ", \n",
      "because \n",
      "that \n",
      "is \n",
      "how \n",
      "i \n",
      "see \n",
      "it \n",
      ", \n",
      "not \n",
      "even \n",
      "as \n",
      "spending \n",
      ", \n",
      "that \n",
      "is \n",
      "just \n",
      "how \n",
      "good \n",
      "it \n",
      "is \n",
      ". \n",
      "i \n",
      "am \n",
      "enthusiastic \n",
      "because \n",
      "this \n",
      "is \n",
      "for \n",
      "sure \n",
      "the \n",
      "best \n",
      "device \n",
      "apple \n",
      "has \n",
      "created \n",
      "in \n",
      "terms \n",
      "of \n",
      "price \n",
      "/ \n",
      "what \n",
      "you \n",
      "get \n",
      ", \n",
      "and \n",
      "it \n",
      "will \n",
      "probably \n",
      "stay \n",
      "in \n",
      "that \n",
      "position \n",
      "for \n",
      "a \n",
      "couple \n",
      "of \n",
      "years \n",
      ". \n",
      "this \n",
      "is \n",
      "game \n",
      "- \n",
      "changing \n",
      "and \n",
      "revolutionary \n",
      ". \n",
      "the \n",
      "computer \n",
      "feels \n",
      "as \n",
      "if \n",
      "it \n",
      "will \n",
      "last \n",
      "10 \n",
      "+ \n",
      "years \n",
      ", \n",
      "honestly \n",
      ". \n",
      "i \n",
      "highly \n",
      "recommend \n",
      "it \n",
      ". \n",
      "btw \n",
      ", \n",
      "it \n",
      "is \n",
      "so \n",
      "good \n",
      "my \n",
      "girlfriend \n",
      "decided \n",
      "to \n",
      "get \n",
      "one \n",
      "for \n",
      "herself \n",
      "because \n",
      "she \n",
      "just \n",
      "could \n",
      "not \n",
      "get \n",
      "over \n",
      "the \n",
      "first \n",
      "time \n",
      "she \n",
      "used \n",
      "it \n",
      ", \n",
      "and \n",
      "just \n",
      "how \n",
      "beautiful \n",
      "it \n",
      "is \n",
      "and \n",
      "pleasurable \n",
      "to \n",
      "look \n",
      "at \n",
      "from \n",
      "any \n",
      "perspective \n",
      "... \n",
      "this \n",
      "laptop \n",
      "is \n",
      "so \n",
      "ridiculously \n",
      "perfect \n",
      "that \n",
      "you \n",
      "can \n",
      "even \n",
      "open \n",
      "it \n",
      "with \n",
      "one \n",
      "hand \n",
      "and \n",
      "in \n",
      "just \n",
      "a \n",
      "couple \n",
      "of \n",
      "seconds \n",
      ", \n",
      "you \n",
      "will \n",
      "be \n",
      "ready \n",
      "to \n",
      "use \n",
      "it \n",
      "as \n",
      "it \n",
      "has \n",
      "an \n",
      "always \n",
      "- \n",
      "on \n",
      "feature \n",
      "that \n",
      "allows \n",
      "you \n",
      "to \n",
      "get \n",
      "down \n",
      "to \n",
      "the \n",
      "working \n",
      "right \n",
      "away \n",
      ". \n",
      "that \n",
      "is \n",
      "probably \n",
      "the \n",
      "best \n",
      "feat \n",
      ". \n",
      "true \n",
      "tone \n",
      "is \n",
      "also \n",
      "really \n",
      "good \n",
      ", \n",
      "as \n",
      "it \n",
      "is \n",
      "automatic \n",
      "brightness \n",
      "adjustment \n",
      "and \n",
      "dark \n",
      "mode \n",
      ", \n",
      "they \n",
      "sit \n",
      "together \n",
      "perfectly \n",
      "well \n",
      ". \n",
      "get \n",
      "it \n",
      "! \n",
      "you \n",
      "will \n",
      "not \n",
      "regret \n",
      "it \n",
      "at \n",
      "any \n",
      "moment \n",
      ". \n",
      "truly \n",
      "a \n",
      "high \n",
      "- \n",
      "end \n",
      "experience \n",
      ". \n",
      "oh \n",
      ", \n",
      "and \n",
      "... \n",
      "it \n",
      "looks \n",
      "elegant \n",
      "at \n",
      "any \n",
      "angle \n",
      ", \n",
      "and \n",
      "which \n",
      "is \n",
      "most \n",
      "important \n",
      ", \n",
      "classy \n",
      "it \n",
      "feels \n",
      ". \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Implementing lemmatization\n",
    "lem = nlp(text)\n",
    "# finding lemma for each word\n",
    "for word in lem:\n",
    "    print(word.text,word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artur\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value [] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omg NOUN\n",
      "! PUNCT\n",
      "this PRON\n",
      "is AUX\n",
      "such DET\n",
      "an DET\n",
      "incredible ADJ\n",
      "product NOUN\n",
      ". PUNCT\n",
      "perfect ADJ\n",
      "keyboard NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "weight NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "battery NOUN\n",
      "life NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "trackpad NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "performance NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "touch NOUN\n",
      "i NOUN\n",
      "d PROPN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "feel NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "build NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "look NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "size NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "stereo NOUN\n",
      "sound NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "screen NOUN\n",
      ", PUNCT\n",
      "perfect ADJ\n",
      "noise NOUN\n",
      "absence NOUN\n",
      "as ADP\n",
      "not PART\n",
      "having VERB\n",
      "a DET\n",
      "fan NOUN\n",
      "! PUNCT\n",
      "i PRON\n",
      "mean VERB\n",
      ", PUNCT\n",
      "it PRON\n",
      "does AUX\n",
      "not PART\n",
      "have VERB\n",
      "a DET\n",
      "fan NOUN\n",
      "and CCONJ\n",
      "it PRON\n",
      "does AUX\n",
      "not PART\n",
      "get VERB\n",
      "hot ADJ\n",
      "most ADJ\n",
      "of ADP\n",
      "the DET\n",
      "times NOUN\n",
      ". PUNCT\n",
      "wtf PROPN\n",
      "? PUNCT\n",
      "! PUNCT\n",
      "it PRON\n",
      "is AUX\n",
      "the DET\n",
      "only ADJ\n",
      "laptop NOUN\n",
      "i PRON\n",
      "have AUX\n",
      "been AUX\n",
      "able ADJ\n",
      "to PART\n",
      "use VERB\n",
      "in ADP\n",
      "my PRON\n",
      "bed NOUN\n",
      "for ADP\n",
      "x SYM\n",
      "amount NOUN\n",
      "of ADP\n",
      "hours NOUN\n",
      "and CCONJ\n",
      "it PRON\n",
      "is AUX\n",
      "sooo ADJ\n",
      "comfortable ADJ\n",
      "to PART\n",
      "do VERB\n",
      "it PRON\n",
      ". PUNCT\n",
      "it PRON\n",
      "truly ADV\n",
      "is AUX\n",
      "one NUM\n",
      "of ADP\n",
      "the DET\n",
      "best ADJ\n",
      "products NOUN\n",
      "out ADV\n",
      "there ADV\n",
      "and CCONJ\n",
      "it PRON\n",
      "is AUX\n",
      "totally ADV\n",
      "worth ADJ\n",
      "the DET\n",
      "investment NOUN\n",
      ", PUNCT\n",
      "because SCONJ\n",
      "that PRON\n",
      "is AUX\n",
      "how SCONJ\n",
      "i PRON\n",
      "see VERB\n",
      "it PRON\n",
      ", PUNCT\n",
      "not PART\n",
      "even ADV\n",
      "as ADP\n",
      "spending NOUN\n",
      ", PUNCT\n",
      "that PRON\n",
      "is AUX\n",
      "just ADV\n",
      "how SCONJ\n",
      "good ADJ\n",
      "it PRON\n",
      "is AUX\n",
      ". PUNCT\n",
      "i PRON\n",
      "am AUX\n",
      "enthusiastic ADJ\n",
      "because SCONJ\n",
      "this PRON\n",
      "is AUX\n",
      "for ADP\n",
      "sure ADJ\n",
      "the DET\n",
      "best ADJ\n",
      "device NOUN\n",
      "apple NOUN\n",
      "has AUX\n",
      "created VERB\n",
      "in ADP\n",
      "terms NOUN\n",
      "of ADP\n",
      "price NOUN\n",
      "/ PUNCT\n",
      "what PRON\n",
      "you PRON\n",
      "get VERB\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "it PRON\n",
      "will AUX\n",
      "probably ADV\n",
      "stay VERB\n",
      "in ADP\n",
      "that DET\n",
      "position NOUN\n",
      "for ADP\n",
      "a DET\n",
      "couple NOUN\n",
      "of ADP\n",
      "years NOUN\n",
      ". PUNCT\n",
      "this PRON\n",
      "is AUX\n",
      "game NOUN\n",
      "- PUNCT\n",
      "changing VERB\n",
      "and CCONJ\n",
      "revolutionary ADJ\n",
      ". PUNCT\n",
      "the DET\n",
      "computer NOUN\n",
      "feels VERB\n",
      "as SCONJ\n",
      "if SCONJ\n",
      "it PRON\n",
      "will AUX\n",
      "last VERB\n",
      "10 NUM\n",
      "+ NUM\n",
      "years NOUN\n",
      ", PUNCT\n",
      "honestly ADV\n",
      ". PUNCT\n",
      "i PRON\n",
      "highly ADV\n",
      "recommend VERB\n",
      "it PRON\n",
      ". PUNCT\n",
      "btw ADV\n",
      ", PUNCT\n",
      "it PRON\n",
      "is AUX\n",
      "so ADV\n",
      "good ADJ\n",
      "my PRON\n",
      "girlfriend NOUN\n",
      "decided VERB\n",
      "to PART\n",
      "get VERB\n",
      "one NUM\n",
      "for ADP\n",
      "herself PRON\n",
      "because SCONJ\n",
      "she PRON\n",
      "just ADV\n",
      "could AUX\n",
      "not PART\n",
      "get VERB\n",
      "over ADP\n",
      "the DET\n",
      "first ADJ\n",
      "time NOUN\n",
      "she PRON\n",
      "used VERB\n",
      "it PRON\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "just ADV\n",
      "how SCONJ\n",
      "beautiful ADJ\n",
      "it PRON\n",
      "is AUX\n",
      "and CCONJ\n",
      "pleasurable ADJ\n",
      "to PART\n",
      "look VERB\n",
      "at ADP\n",
      "from ADP\n",
      "any DET\n",
      "perspective NOUN\n",
      "... PUNCT\n",
      "this DET\n",
      "laptop NOUN\n",
      "is AUX\n",
      "so ADV\n",
      "ridiculously ADV\n",
      "perfect ADJ\n",
      "that SCONJ\n",
      "you PRON\n",
      "can AUX\n",
      "even ADV\n",
      "open VERB\n",
      "it PRON\n",
      "with ADP\n",
      "one NUM\n",
      "hand NOUN\n",
      "and CCONJ\n",
      "in ADP\n",
      "just ADV\n",
      "a DET\n",
      "couple NOUN\n",
      "of ADP\n",
      "seconds NOUN\n",
      ", PUNCT\n",
      "you PRON\n",
      "will AUX\n",
      "be AUX\n",
      "ready ADJ\n",
      "to PART\n",
      "use VERB\n",
      "it PRON\n",
      "as SCONJ\n",
      "it PRON\n",
      "has VERB\n",
      "an DET\n",
      "always ADV\n",
      "- PUNCT\n",
      "on ADP\n",
      "feature NOUN\n",
      "that PRON\n",
      "allows VERB\n",
      "you PRON\n",
      "to PART\n",
      "get VERB\n",
      "down ADP\n",
      "to ADP\n",
      "the DET\n",
      "working NOUN\n",
      "right ADV\n",
      "away ADV\n",
      ". PUNCT\n",
      "that PRON\n",
      "is AUX\n",
      "probably ADV\n",
      "the DET\n",
      "best ADJ\n",
      "feat NOUN\n",
      ". PUNCT\n",
      "true ADJ\n",
      "tone NOUN\n",
      "is AUX\n",
      "also ADV\n",
      "really ADV\n",
      "good ADJ\n",
      ", PUNCT\n",
      "as SCONJ\n",
      "it PRON\n",
      "is AUX\n",
      "automatic ADJ\n",
      "brightness NOUN\n",
      "adjustment NOUN\n",
      "and CCONJ\n",
      "dark ADJ\n",
      "mode NOUN\n",
      ", PUNCT\n",
      "they PRON\n",
      "sit VERB\n",
      "together ADV\n",
      "perfectly ADV\n",
      "well ADV\n",
      ". PUNCT\n",
      "get VERB\n",
      "it PRON\n",
      "! PUNCT\n",
      "you PRON\n",
      "will AUX\n",
      "not PART\n",
      "regret VERB\n",
      "it PRON\n",
      "at ADP\n",
      "any DET\n",
      "moment NOUN\n",
      ". PUNCT\n",
      "truly ADV\n",
      "a DET\n",
      "high ADJ\n",
      "- PUNCT\n",
      "end NOUN\n",
      "experience NOUN\n",
      ". PUNCT\n",
      "oh INTJ\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "... PUNCT\n",
      "it PRON\n",
      "looks VERB\n",
      "elegant ADJ\n",
      "at ADP\n",
      "any DET\n",
      "angle NOUN\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "which PRON\n",
      "is AUX\n",
      "most ADV\n",
      "important ADJ\n",
      ", PUNCT\n",
      "classy ADJ\n",
      "it PRON\n",
      "feels VERB\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n"
     ]
    }
   ],
   "source": [
    "# POS tagging\n",
    "\n",
    "# importing the model en_core_web_sm of English for vocabluary, syntax & entities\n",
    "import en_core_web_sm\n",
    "\n",
    "# load en_core_web_sm of English for vocabluary, syntax & entities\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#  \"nlp\" Objectis used to create documents with linguistic annotations.\n",
    "docs = nlp(text)\n",
    "\n",
    "for word in docs:\n",
    "    print(word.text,word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(hours, 'TIME', 392),\n",
       " (a couple of years, 'DATE', 391),\n",
       " (last 10+ years, 'DATE', 391),\n",
       " (first, 'ORDINAL', 396),\n",
       " (just a couple of seconds, 'TIME', 392)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for visualization of Entity detection importing displacy from spacy:\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "text2 = nlp(text)\n",
    "\n",
    "entities=[(i, i.label_, i.label) for i in text2.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">omg! this is such an incredible product. perfect keyboard, perfect weight, perfect battery life, perfect trackpad, perfect performance, perfect touch id, perfect feel, perfect build, perfect look, perfect size, perfect stereo sound, perfect screen, perfect noise absence as not having a fan! i mean, it does not have a fan and it does not get hot most of the times. wtf?! it is the only laptop i have been able to use in my bed for x amount of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hours\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " and it is sooo comfortable to do it. it truly is one of the best products out there and it is totally worth the investment, because that is how i see it, not even as spending, that is just how good it is. i am enthusiastic because this is for sure the best device apple has created in terms of price/what you get, and it will probably stay in that position for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a couple of years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". this is game-changing and revolutionary. the computer feels as if it will \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last 10+ years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", honestly. i highly recommend it. btw, it is so good my girlfriend decided to get one for herself because she just could not get over the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " time she used it, and just how beautiful it is and pleasurable to look at from any perspective... this laptop is so ridiculously perfect that you can even open it with one hand and in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    just a couple of seconds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ", you will be ready to use it as it has an always-on feature that allows you to get down to the working right away. that is probably the best feat. true tone is also really good, as it is automatic brightness adjustment and dark mode, they sit together perfectly well. get it! you will not regret it at any moment. truly a high-end experience. oh, and... it looks elegant at any angle, and which is most important, classy it feels.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(text2, style = \"ent\",jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pursuit pursuit pobj In\n",
      "a wall wall pobj of\n",
      "President Trump Trump nsubj ran\n"
     ]
    }
   ],
   "source": [
    "docp = nlp(\" In pursuit of a wall, President Trump ran into one.\")\n",
    "\n",
    "for chunk in docp.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "        chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ddd16970007241f38db517abedcd3b98-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pursuit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">wall,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">President</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Trump</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">ran</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">into</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">one.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd16970007241f38db517abedcd3b98-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd16970007241f38db517abedcd3b98-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docp, style=\"dep\", jupyter= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors and Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "[ 0.67121375  0.547875    1.1662204  -0.8862695  -0.7446909   1.4388278\n",
      " -0.0310275   0.14206484  1.4838524  -1.1957114   0.08386576 -0.911056\n",
      "  0.05417725 -0.10735506 -1.0579314   0.1266487  -0.2706933   1.569655\n",
      "  0.9489083  -0.14418542  0.3911935  -0.14170304 -0.7126999   1.6709299\n",
      "  0.7659299   1.1870233   0.08993122  0.7558858   0.2850564   1.481607\n",
      " -0.04087245 -0.34370816 -0.64876366 -1.1423168  -0.4228799   1.2094326\n",
      " -0.03956398  0.2813167   0.54050326  0.3834293  -0.26618952  0.14527136\n",
      " -1.0663483  -0.21301082 -0.00739029 -2.210084    0.540864    1.0819434\n",
      "  0.66898596 -1.1011103   0.07047433 -1.638876   -0.7076828  -1.7068787\n",
      "  0.42300764 -0.5747217  -1.5162356  -1.0353892  -0.18434292 -0.32043636\n",
      " -0.588754   -0.7868452  -0.9719215  -0.7482023  -0.24716026 -0.25685\n",
      " -0.19451576  1.3188727  -0.08707494 -1.3416569   2.2506413  -0.02113014\n",
      "  0.23767492  0.57176274  0.35061055 -0.598348    1.028291    0.1865943\n",
      " -0.03997174  1.0957274  -0.20389979 -0.5785228  -0.31933782 -0.49575502\n",
      "  1.0698853   1.1163912   0.44036973  1.3415468  -1.4426728   0.02960265\n",
      " -0.82188195 -1.3802235  -1.2823546   2.5000155  -0.04510635  1.9417986 ]\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "mango = nlp(u'mango')\n",
    "print(mango.vector.shape)\n",
    "print(mango.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10648701098514877540 aspect 1 2 battery\n",
      "10648701098514877540 aspect 5 6 battery\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"battery\"}]\n",
    "matcher.add(\"aspect\", [pattern])\n",
    "\n",
    "doc = nlp(\"The battery life is excellent battery\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matched_sents = []  # Collect data of matched sentences to be visualized\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]  # Matched span\n",
    "    sent = span.sent  # Sentence containing matched span\n",
    "    # Append mock entity for match in displaCy style to matched_sents\n",
    "    # get the match span by ofsetting the start and end of the span with the\n",
    "    # start and end of the sentence in the doc\n",
    "    match_ents = [{\n",
    "        \"start\": span.start_char - sent.start_char,\n",
    "        \"end\": span.end_char - sent.start_char,\n",
    "        \"label\": \"MATCH\",\n",
    "    }]\n",
    "    matched_sents.append({\"text\": sent.text, \"ents\": match_ents})\n",
    "\n",
    "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"},\n",
    "            {\"POS\": \"ADJ\"}]\n",
    "matcher.add(\"FacebookIs\", [pattern], on_match=collect_sents)  # add pattern\n",
    "doc = nlp(\"\"\"omg! this is such an incredible product. perfect keyboard, perfect weight, perfect battery life, perfect trackpad, perfect performance, perfect touch id, perfect feel, perfect build, perfect look, perfect size, perfect stereo sound, perfect screen, perfect noise absence as not having a fan! i mean, it does not have a fan and it does not get hot most of the times. wtf?! it is the only laptop i have been able to use in my bed for x amount of hours and it is sooo comfortable to do it. it truly is one of the best products out there and it is totally worth the investment, because that is how i see it, not even as spending, that is just how good it is. i am enthusiastic because this is for sure the best device apple has created in terms of price/what you get, and it will probably stay in that position for a couple of years. this is game-changing and revolutionary. the computer feels as if it will last 10+ years, honestly. i highly recommend it. btw, it is so good my girlfriend decided to get one for herself because she just could not get over the first time she used it, and just how beautiful it is and pleasurable to look at from any perspective... this laptop is so ridiculously perfect that you can even open it with one hand and in just a couple of seconds, you will be ready to use it as it has an always-on feature that allows you to get down to the working right away. that is probably the best feat. true tone is also really good, as it is automatic brightness adjustment and dark mode, they sit together perfectly well. get it! you will not regret it at any moment. truly a high-end experience. oh, and... it looks elegant at any angle, and which is most important, classy it feels.\n",
    "\"\"\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Serve visualization of sentences containing match with displaCy\n",
    "# set manual=True to make displaCy render straight from a dictionary\n",
    "# (if you're not running the code within a Jupyer environment, you can\n",
    "# use displacy.serve instead)\n",
    "displacy.render(matched_sents, style=\"ent\", manual=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c395646f09c62cd0a4225eecbf7f0db2b540a0317614e24b8da97c89261644e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
